}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=2,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
View(tw_df)
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
View(tw_df)
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ")
}
c<-sapply(tw_df$text,f)
c
a
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ")
}
c<-sapply(tw_df$text,f)
c
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
# dat4 <- dat2[-dat3]
#  dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
# dat4 <- dat2[-dat3]
#  dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
#  dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grep("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[-dat3]
dat5 <- paste(dat4, collapse = " ,")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ,")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
View(tw_df)
tweets<-searchTwitter("iphone", n=10,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
myCorpus <- Corpus(VectorSource(tw_df$text))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myStopwords <- c(stopwords('english'))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
dictCorpus <- myCorpus
library(SnowballC)
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
# inspect the first three ``documents"
inspect(myCorpus[1:3])
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
inspect(myCorpus[1:3])
inspect(myCorpus[1:3])
myCorpus<-m_map(myCorpus, stripWhitespace)
myCorpus<-tm_map(myCorpus, stripWhitespace)
inspect(myCorpus[1:3])
hu.liu.pos<-scan("positive-words.txt", what="character", comment.char=";")
setwd("C:/Projects/ShinyApps/DataAnalysis/temp.Shiny")
hu.liu.pos<-scan("positive-words.txt", what="character", comment.char=";")
hu.liu.neg<-scan("negative-words.txt", what="character", comment.char=";")
myCorpus$text
myCorpus[[1]]$text
myCorpus[[1]]
myCorpus[[1]]%in%hu.liu.pos
c("good", bad") %in%hu.liu.pos
)
)
))))
""
c("good", bad") %in% hu.liu.pos
""
c("good", "bad") %in% hu.liu.pos
pos<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.pos))
pos
pos<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.neg))
neg<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.neg))
neg
tweets<-searchTwitter("iphone", n=1000,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
myCorpus <- Corpus(VectorSource(tw_df$text))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myStopwords <- c(stopwords('english'))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
dictCorpus <- myCorpus
library(SnowballC)
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
# inspect the first three ``documents"
inspect(myCorpus[1:3])
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
tweets<-searchTwitter("iphone", n=1000,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
myCorpus <- Corpus(VectorSource(tw_df$text))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myStopwords <- c(stopwords('english'))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
dictCorpus <- myCorpus
library(SnowballC)
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
# inspect the first three ``documents"
inspect(myCorpus[1:3])
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
inspect(myCorpus[1:3])
myCorpus<-tm_map(myCorpus, stripWhitespace)
inspect(myCorpus[1:3])
hu.liu.pos<-scan("positive-words.txt", what="character", comment.char=";")
hu.liu.neg<-scan("negative-words.txt", what="character", comment.char=";")
pos<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.pos))
neg<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.neg))
myDtm <- TermDocumentMatrix(myCorpus, control = list(minWordLength = 1))
neg
sum(neg)
pos<-lapply(myCorpus$text,function(x) sum(strsplit(x," ") %in% hu.liu.pos))
neg<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.neg))
neg
myCorpus$text
str(myCorpus)
str(myCorpus$text)
str(myCorpus[[1]])
class(myCorpus[[1]])
myCorpus[[1]]
pos<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.pos))
pos
?corpus
?Corpus
pos<-lapply(myCorpus,function(x) sum(strsplit(x$text," ") %in% hu.liu.pos))
strsplit(myCorpus[[1]]," ")
pos<-sum(lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.pos)))
neg<-sum(lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.neg)))
pos<-lapply(myCorpus,function(x) sum(strsplit(x," ") %in% hu.liu.pos))
poa
pos
sum(pos)
sum(unlist(pos)
)
hu.liu.pos
aa<-c("good")
aa%in%hu.liu.pos
aa<-c("good","good","bad")
sum(aa%in%hu.liu.pos)
sum(strsplit(myCorpus[[1]]," ") %in% hu.liu.pos
)
sum(strsplit(myCorpus[[1]]," ") %in% hu.liu.pos
)
sum(strsplit(myCorpus[[1]]," ") %in% hu.liu.pos)
myCorpus[[1]]
"love" %in% hu.liu.pos
strsplit(myCorpus," ")
strsplit(myCorpus[[1]]," ")
strsplit(myCorpus[[1]]," ") %in% hu.liu.pos
?%in%
pos<-lapply(myCorpus,function(x) strsplit(x," "))
DIM(POS)
dim(pos)
pos
pos<-sapply(myCorpus,function(x) strsplit(x," "))
pos
pos1<-sapply(pos,function(x) sum(x%in%hu.liu.pos))
pos<-sapply(myCorpus,function(x) strsplit(x," "))
pos1<-sapply(pos,function(x) sum(x%in%hu.liu.pos))
neg1<-sapply(pos,function(x) sum(x%in%hu.liu.neg))
sen<-pos1-neg1
plot(sen)
b<-sen(1:5)
sen<-pos1-neg1
b<-sen(1:5)
b<-sen[1:5]
sen<-pos1-neg1
movea<-5;
for(i in seq(1000-movea))
{
a(i)<-sum(sen[i:i+movea])
}
b<-sen[1:5]
a(i)<-sum(sen[i:i+movea])
movea<-5;
for(i in seq(1000-movea))
{
a[i]<-sum(sen[i:i+movea])
}
plot(a)
plot(a)
plot(sen)
a
plot(a)
plot(unlist(a)
plot(unlist(a))
b<-unlist(a)
plot(b)
plot(sen)
plot(b)
movea<-20;
for(i in seq(1000-movea))
{
a[i]<-sum(sen[i:i+movea])
}
b<-unlist(a)
plot(b)
plot(b,type="l")
a
sen
head(sen)
head(a)
head(b)
head(sen)
sum(sen[1:5])
a[1]
sum(sen[1:5])
sum(sen[2:6])
for(i in seq(1000-movea))
{
d[i]<-sum(sen[i:i+movea])
}
d
d[1]
for(i in seq(1000-movea))
{
d[i]<-sum(sen[i:i+movea])
}
d[1]
sen
seq(1000-movea)
i in seq(1000-movea
seq(2)
sum(sen[2:2+movea]
)
sum(sen[2:2+movea])
sum(sen[3:3+movea])
sum(sen[1:1+movea])
pos<-sapply(myCorpus,function(x) strsplit(x," "))
pos1<-sapply(pos,function(x) sum(x%in%hu.liu.pos))
neg1<-sapply(pos,function(x) sum(x%in%hu.liu.neg))
sen<-pos1-neg1
movea<-20;
for(i in seq(1000-movea))
{
d[i]<-sum(sen[i:i+movea])
}
d
sen
for(i in seq(1000-movea))
{
a<-sum(sen[i:i+movea])
}
d
for(i in seq(1000-movea))
{
ax<-sum(sen[i:i+movea])
}
sen
bx<-unlist(a)
bx
ax
sen
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
ax
sen
movea<-10;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
sen
plot(ax)
movea<-20;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
plot(ax)
sen
plot(ax,type="l")
plot(sen,type="l")
plot(ax,type="l")
plot(sen,type="l")
movea<-5;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
plot(ax,type="l")
plot(sen,type="l")
ax[1]
sen[1:5]
movea<-5;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
plot(ax,type="l")
plot(sen,type="l")
ax{1}
ax[1]
sen[1:5]
sum(sen[1:1+movea]
)
sum(sen[1:1+movea])
sen[1:1+movea]
sen
movea<-5;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
sen[1]
sen[1:5]
ax[1]
sum(sen[i:i+movea])
sum(sen[1:1+movea])
sen[1:5]
sum(sen[1:1+movea])
?sum
str(sen)
?sum(c(1,2))
sum(c(1,2))
sum(sen[1:1+movea])
sen[1:1+movea]
sen[1:1+movea]
pos<-sapply(myCorpus,function(x) strsplit(x," "))
pos1<-sapply(pos,function(x) sum(x%in%hu.liu.pos))
neg1<-sapply(pos,function(x) sum(x%in%hu.liu.neg))
sen<-pos1-neg1
movea<-5;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:i+movea])
}
plot(ax,type="l")
ax[1]
?sum
dim(sen)
sen
class(sen)
length(sen)
sum(sen(1:5))
sum(sen[1:5])
movea
sen[1;6]
sen[1:6]
sum(sen[1:5])
sum(sen[1:6])
movea<-5;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:(i+movea)])
}
plot(ax,type="l")
ax[1]
sen[1:5]
plot(sen,type="l")
plot(ax,type="l")
movea<-10;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:(i+movea)])
}
plot(ax,type="l")
movea<-100;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:(i+movea)])
}
plot(ax,type="l")
library(tm)
tweets<-searchTwitter("nq price", n=1000,lang="en")
tw_df<-do.call("rbind", lapply(tweets, as.data.frame))
f<-function(x) {
dat2 <- unlist(strsplit(x, split=" "))
dat3 <- grepl("dat2", iconv(dat2, "latin1", "ASCII", sub="dat2"))
dat4 <- dat2[!dat3]
dat5 <- paste(dat4, collapse = " ")
}
tw_df$text<-sapply(tw_df$text,f)
myCorpus <- Corpus(VectorSource(tw_df$text))
myCorpus <- tm_map(myCorpus, removePunctuation)
myCorpus <- tm_map(myCorpus, removeNumbers)
myCorpus <- tm_map(myCorpus, tolower)
myStopwords <- c(stopwords('english'))
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
dictCorpus <- myCorpus
library(SnowballC)
# which requires packages Snowball, RWeka, rJava, RWekajars
myCorpus <- tm_map(myCorpus, stemDocument)
# inspect the first three ``documents"
inspect(myCorpus[1:3])
myCorpus <- tm_map(myCorpus, stemCompletion, dictionary=dictCorpus)
inspect(myCorpus[1:3])
myCorpus<-tm_map(myCorpus, stripWhitespace)
inspect(myCorpus[1:3])
hu.liu.pos<-scan("positive-words.txt", what="character", comment.char=";")
hu.liu.neg<-scan("negative-words.txt", what="character", comment.char=";")
sp<-function(x) x %in% hu.liu.pos
sn<-function(x) x %in% hu.liu.pos
pos<-sapply(myCorpus,function(x) strsplit(x," "))
pos1<-sapply(pos,function(x) sum(x%in%hu.liu.pos))
neg1<-sapply(pos,function(x) sum(x%in%hu.liu.neg))
sen<-pos1-neg1
movea<-100;
for(i in seq(1000-movea))
{
ax[i]<-sum(sen[i:(i+movea)])
}
plot(ax,type="l")
